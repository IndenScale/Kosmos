#!/usr/bin/env python3
"""
Kosmos Knowledge Base MCP Server

ä¸€ä¸ªç”¨äºè®¿é—®è¿œç¨‹KosmosçŸ¥è¯†åº“çš„MCPæœåŠ¡å™¨ï¼Œæä¾›è¯­ä¹‰æœç´¢å’ŒçŸ¥è¯†åº“æŸ¥è¯¢åŠŸèƒ½ã€‚
"""

import asyncio
import json
import os
from typing import Any, Sequence, Optional, List, Dict
from urllib.parse import urljoin
import aiohttp
from dotenv import load_dotenv

from mcp.server.models import InitializationOptions
from mcp.server import NotificationOptions, Server
from mcp.types import (
    Resource,
    Tool,
    TextContent,
    ImageContent,
    EmbeddedResource,
    LoggingLevel
)
from pydantic.networks import AnyUrl
import mcp.types as types

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class KosmosClient:
    """Kosmos APIå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, username: Optional[str] = None, password: Optional[str] = None):
        self.base_url = base_url.rstrip('/')
        self.username = username
        self.password = password
        self.session: Optional[aiohttp.ClientSession] = None
        self.auth_token: Optional[str] = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        await self._authenticate()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def _authenticate(self):
        """è®¤è¯è·å–token"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        if self.username and self.password:
            # ä½¿ç”¨ä¸auth.pyä¸€è‡´çš„tokenç«¯ç‚¹
            auth_url = urljoin(self.base_url, '/api/v1/auth/token')
            auth_data = {
                'username': self.username,
                'password': self.password
            }
            try:
                # ä½¿ç”¨form dataè€Œä¸æ˜¯jsonï¼Œä¸OAuth2PasswordRequestFormä¿æŒä¸€è‡´
                async with self.session.post(auth_url, data=auth_data) as response:
                    if response.status == 200:
                        result = await response.json()
                        self.auth_token = result.get('access_token')
                        if not self.auth_token:
                            print(f"è­¦å‘Š: è®¤è¯å“åº”ä¸­æœªæ‰¾åˆ°access_token: {result}")
                    elif response.status == 401:
                        print(f"è®¤è¯å¤±è´¥: ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
                    else:
                        response_text = await response.text()
                        print(f"è®¤è¯å¤±è´¥: HTTP {response.status} - {response_text}")
            except Exception as e:
                print(f"è®¤è¯è¿‡ç¨‹å‡ºé”™: {e}")
                # å¦‚æœè®¤è¯å¤±è´¥ï¼Œå°è¯•ä¸ä½¿ç”¨è®¤è¯ï¼ˆå¯¹äºå…¬å…±çŸ¥è¯†åº“ï¼‰
                pass
    
    def _get_headers(self):
        """è·å–è¯·æ±‚å¤´"""
        headers = {'Content-Type': 'application/json'}
        if self.auth_token:
            headers['Authorization'] = f'Bearer {self.auth_token}'
        return headers
    
    async def list_knowledge_bases(self) -> List[Dict]:
        """åˆ—å‡ºçŸ¥è¯†åº“"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, '/api/v1/kbs/')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“åˆ—è¡¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_knowledge_base(self, kb_id: str) -> Dict:
        """è·å–çŸ¥è¯†åº“è¯¦æƒ…"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/kbs/{kb_id}')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“ {kb_id}")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–çŸ¥è¯†åº“è¯¦æƒ…å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def search_knowledge_base(self, kb_id: str, query: str, top_k: int = 10) -> Dict:
        """åœ¨çŸ¥è¯†åº“ä¸­æ‰§è¡Œè¯­ä¹‰æœç´¢
        
        æ”¯æŒå¤åˆæŸ¥è¯¢è¯­æ³•ï¼š
        - æ™®é€šè¯æ±‡ï¼šç›´æ¥åŒ¹é…
        - +è¯æ±‡ï¼šå¿…é¡»åŒ…å«
        - -è¯æ±‡ï¼šå¿…é¡»æ’é™¤ 
        - ~æ ‡ç­¾ï¼šæŒ‰æ ‡ç­¾è¿‡æ»¤
        """
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/kbs/{kb_id}/search')
        headers = self._get_headers()
        data = {
            'query': query,
            'top_k': top_k
        }
        
        async with self.session.post(url, json=data, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™æœç´¢çŸ¥è¯†åº“ {kb_id}")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            elif response.status == 422:
                response_text = await response.text()
                raise Exception(f"æœç´¢å‚æ•°é”™è¯¯: {response_text}")
            else:
                response_text = await response.text()
                raise Exception(f"æœç´¢å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_chunk(self, chunk_id: str) -> Dict:
        """æ ¹æ®IDè·å–chunkè¯¦æƒ…"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/chunks/{chunk_id}')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 404:
                raise Exception(f"æ–‡æ¡£ç‰‡æ®µ {chunk_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–chunkå¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_knowledge_base_stats(self, kb_id: str) -> Dict:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/kbs/{kb_id}/stats')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“ {kb_id} çš„ç»Ÿè®¡ä¿¡æ¯")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–çŸ¥è¯†åº“ç»Ÿè®¡å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_knowledge_base_health(self, kb_id: str) -> Dict:
        """è·å–çŸ¥è¯†åº“å¥åº·åº¦ç›‘æµ‹ä¿¡æ¯ï¼ˆSDTMç»Ÿè®¡ï¼‰"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/sdtm/{kb_id}/stats')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“ {kb_id} çš„å¥åº·åº¦ä¿¡æ¯")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–çŸ¥è¯†åº“å¥åº·åº¦å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_abnormal_documents(self, kb_id: str, limit: int = 3) -> Dict:
        """è·å–å¼‚å¸¸æ–‡æ¡£åˆ—è¡¨ï¼ˆé™åˆ¶æ•°é‡ä»¥é¿å…ä¸Šä¸‹æ–‡æ±¡æŸ“ï¼‰"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/sdtm/{kb_id}/abnormal-documents')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                result = await response.json()
                # æŒ‰å¼‚å¸¸ç±»å‹åˆ†ç»„å¹¶é™åˆ¶æ¯ç±»çš„æ•°é‡
                if result.get('abnormal_documents'):
                    grouped = {}
                    for doc in result['abnormal_documents']:
                        anomaly_type = doc.get('anomaly_type', 'unknown')
                        if anomaly_type not in grouped:
                            grouped[anomaly_type] = []
                        if len(grouped[anomaly_type]) < limit:
                            grouped[anomaly_type].append(doc)
                    
                    # é‡æ–°ç»„ç»‡ç»“æœ
                    result['abnormal_documents_by_type'] = grouped
                    result['abnormal_documents'] = []
                    for docs in grouped.values():
                        result['abnormal_documents'].extend(docs)
                
                return result
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“ {kb_id} çš„å¼‚å¸¸æ–‡æ¡£")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–å¼‚å¸¸æ–‡æ¡£å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def start_health_optimization(self, kb_id: str, mode: str = "shadow", batch_size: int = 10) -> Dict:
        """å¯åŠ¨çŸ¥è¯†åº“å¥åº·åº¦ä¼˜åŒ–ä»»åŠ¡"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/sdtm/{kb_id}/optimize')
        headers = self._get_headers()
        data = {
            'mode': mode,
            'batch_size': batch_size,
            'auto_apply': mode != 'shadow',  # å½±å­æ¨¡å¼ä¸è‡ªåŠ¨åº”ç”¨
            'abnormal_doc_slots': 3,
            'normal_doc_slots': 7,
            'max_iterations': 50,
            'abnormal_doc_threshold': 3.0,
            'enable_early_termination': True
        }
        
        async with self.session.post(url, json=data, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™å¯åŠ¨çŸ¥è¯†åº“ {kb_id} çš„ä¼˜åŒ–ä»»åŠ¡")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"å¯åŠ¨ä¼˜åŒ–ä»»åŠ¡å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_optimization_jobs(self, kb_id: str) -> Dict:
        """è·å–çŸ¥è¯†åº“ä¼˜åŒ–ä»»åŠ¡åˆ—è¡¨"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/sdtm/{kb_id}/jobs')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“ {kb_id} çš„ä»»åŠ¡åˆ—è¡¨")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_optimization_job_status(self, kb_id: str, job_id: str) -> Dict:
        """è·å–ä¼˜åŒ–ä»»åŠ¡çŠ¶æ€"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/sdtm/{kb_id}/jobs/{job_id}')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®ä»»åŠ¡ {job_id}")
            elif response.status == 404:
                raise Exception(f"ä»»åŠ¡ {job_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_tagging_stats(self, kb_id: str) -> Dict:
        """è·å–æ ‡ç­¾ç»Ÿè®¡ä¿¡æ¯"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/tagging/{kb_id}/stats')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“ {kb_id} çš„æ ‡ç­¾ç»Ÿè®¡")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–æ ‡ç­¾ç»Ÿè®¡å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_untagged_chunks(self, kb_id: str, limit: int = 10) -> Dict:
        """è·å–æœªæ ‡æ³¨çš„æ–‡æ¡£ç‰‡æ®µ"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/api/v1/tagging/{kb_id}/untagged-chunks')
        headers = self._get_headers()
        params = {'limit': limit}
        
        async with self.session.get(url, headers=headers, params=params) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™è®¿é—®çŸ¥è¯†åº“ {kb_id} çš„æœªæ ‡æ³¨ç‰‡æ®µ")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–æœªæ ‡æ³¨ç‰‡æ®µå¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def start_tagging_task(self, kb_id: str, document_id: str = None, chunk_ids: list = None) -> Dict:
        """å¯åŠ¨æ ‡æ³¨ä»»åŠ¡"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        if document_id:
            url = urljoin(self.base_url, f'/api/v1/tagging/{kb_id}/tag-document/{document_id}')
            data = {}
        else:
            url = urljoin(self.base_url, f'/api/v1/tagging/{kb_id}/tag-chunks')
            data = {'chunk_ids': chunk_ids} if chunk_ids else {}
        
        headers = self._get_headers()
        
        async with self.session.post(url, json=data, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 403:
                raise Exception(f"ç¦æ­¢è®¿é—®: ç”¨æˆ·æ²¡æœ‰æƒé™å¯åŠ¨æ ‡æ³¨ä»»åŠ¡")
            elif response.status == 404:
                raise Exception(f"çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"å¯åŠ¨æ ‡æ³¨ä»»åŠ¡å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_document_screenshots(self, document_id: str) -> Dict:
        """è·å–æ–‡æ¡£æˆªå›¾ä¿¡æ¯"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/screenshots/document/{document_id}')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 404:
                raise Exception(f"æ–‡æ¡£ {document_id} ä¸å­˜åœ¨æˆ–æ— æˆªå›¾")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–æ–‡æ¡£æˆªå›¾å¤±è´¥: HTTP {response.status} - {response_text}")
    
    async def get_screenshot_info(self, screenshot_id: str) -> Dict:
        """è·å–æˆªå›¾è¯¦ç»†ä¿¡æ¯"""
        if not self.session:
            raise Exception("Sessionæœªåˆå§‹åŒ–")
            
        url = urljoin(self.base_url, f'/screenshots/{screenshot_id}/info')
        headers = self._get_headers()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                return await response.json()
            elif response.status == 401:
                raise Exception(f"æœªæˆæƒè®¿é—®: è¯·æ£€æŸ¥è®¤è¯é…ç½®")
            elif response.status == 404:
                raise Exception(f"æˆªå›¾ {screenshot_id} ä¸å­˜åœ¨")
            else:
                response_text = await response.text()
                raise Exception(f"è·å–æˆªå›¾ä¿¡æ¯å¤±è´¥: HTTP {response.status} - {response_text}")

# åˆ›å»ºMCPæœåŠ¡å™¨å®ä¾‹
server = Server("kosmos-knowledge-base")

@server.list_resources()
async def handle_list_resources() -> list[Resource]:
    """åˆ—å‡ºå¯ç”¨çš„èµ„æº"""
    return [
        Resource(
            uri=AnyUrl("kosmos://knowledge-bases"),
            name="çŸ¥è¯†åº“åˆ—è¡¨",
            description="è·å–æ‰€æœ‰å¯è®¿é—®çš„çŸ¥è¯†åº“åˆ—è¡¨",
            mimeType="application/json"
        )
    ]

@server.read_resource()
async def handle_read_resource(uri: AnyUrl) -> str:
    """è¯»å–èµ„æºå†…å®¹"""
    if str(uri) == "kosmos://knowledge-bases":
        base_url = os.getenv('KOSMOS_BASE_URL')
        if not base_url:
            return "é”™è¯¯: æœªé…ç½®KOSMOS_BASE_URLç¯å¢ƒå˜é‡"
            
        try:
            async with KosmosClient(
                base_url=base_url,
                username=os.getenv('KOSMOS_USERNAME'),
                password=os.getenv('KOSMOS_PASSWORD'),
            ) as client:
                kbs = await client.list_knowledge_bases()
                return json.dumps(kbs, ensure_ascii=False, indent=2)
        except Exception as e:
            return f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {str(e)}"
    else:
        raise ValueError(f"æœªçŸ¥èµ„æº: {uri}")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    """åˆ—å‡ºå¯ç”¨çš„å·¥å…·"""
    return [
        Tool(
            name="list_knowledge_bases",
            description="åˆ—å‡ºæ‰€æœ‰å¯è®¿é—®çš„çŸ¥è¯†åº“",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        ),
        Tool(
            name="get_knowledge_base",
            description="è·å–æŒ‡å®šçŸ¥è¯†åº“çš„è¯¦ç»†ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="search_knowledge_base",
            description="åœ¨æŒ‡å®šçŸ¥è¯†åº“ä¸­è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œæ”¯æŒæ ‡ç­¾è¿‡æ»¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    },
                    "query": {
                        "type": "string",
                        "description": "æœç´¢æŸ¥è¯¢ï¼Œæ”¯æŒå¤åˆæŸ¥è¯¢è¯­æ³•ï¼šæ™®é€šè¯æ±‡ã€+å¿…é¡»åŒ…å«ã€-å¿…é¡»æ’é™¤ã€~æ ‡ç­¾è¿‡æ»¤ï¼ˆå¦‚ï¼š'AIæœªæ¥å‘å±• +æŠ€æœ¯ -å†å² ~åº”ç”¨'ï¼‰"
                    },
                    "top_k": {
                        "type": "integer",
                        "description": "è¿”å›ç»“æœæ•°é‡ï¼ˆæœ€å¤š50ï¼‰",
                        "default": 10,
                        "minimum": 1,
                        "maximum": 50
                    }
                },
                "required": ["kb_id", "query"]
            }
        ),
        Tool(
            name="get_chunk",
            description="æ ¹æ®IDè·å–æ–‡æ¡£ç‰‡æ®µçš„è¯¦ç»†ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {
                    "chunk_id": {
                        "type": "string",
                        "description": "æ–‡æ¡£ç‰‡æ®µID"
                    }
                },
                "required": ["chunk_id"]
            }
        ),
        Tool(
            name="get_knowledge_base_stats",
            description="è·å–çŸ¥è¯†åº“çš„ç»Ÿè®¡ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="monitor_knowledge_base_health",
            description="ç›‘æµ‹çŸ¥è¯†åº“å¥åº·åº¦ï¼Œæ£€æŸ¥æ ‡ç­¾è´¨é‡ã€æ–‡æ¡£æ ‡æ³¨çŠ¶æ€ç­‰æŒ‡æ ‡",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="get_problematic_documents",
            description="è·å–æœ‰é—®é¢˜çš„æ–‡æ¡£åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ ‡æ³¨ä¸è¶³ã€æ ‡æ³¨è¿‡åº¦ã€æ— æ³•åŒºåˆ†çš„æ–‡æ¡£",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    },
                    "samples_per_type": {
                        "type": "integer",
                        "description": "æ¯ç§å¼‚å¸¸ç±»å‹è¿”å›çš„æ ·æœ¬æ•°é‡",
                        "default": 3,
                        "minimum": 1,
                        "maximum": 10
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="start_health_optimization",
            description="å¯åŠ¨çŸ¥è¯†åº“å¥åº·åº¦ä¼˜åŒ–ä»»åŠ¡ï¼Œå¯ä»¥é€‰æ‹©å½±å­æ¨¡å¼ï¼ˆä»…åˆ†æï¼‰æˆ–ç¼–è¾‘æ¨¡å¼ï¼ˆè‡ªåŠ¨ä¿®å¤ï¼‰",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    },
                    "mode": {
                        "type": "string",
                        "description": "ä¼˜åŒ–æ¨¡å¼ï¼šshadowï¼ˆå½±å­æ¨¡å¼ï¼Œä»…åˆ†æä¸ä¿®æ”¹ï¼‰ã€editï¼ˆç¼–è¾‘æ¨¡å¼ï¼Œè‡ªåŠ¨ä¿®å¤ï¼‰",
                        "enum": ["shadow", "edit"],
                        "default": "shadow"
                    },
                    "batch_size": {
                        "type": "integer",
                        "description": "æ‰¹å¤„ç†å¤§å°",
                        "default": 10,
                        "minimum": 1,
                        "maximum": 50
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="get_optimization_jobs",
            description="è·å–çŸ¥è¯†åº“ä¼˜åŒ–ä»»åŠ¡åˆ—è¡¨å’ŒçŠ¶æ€",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="get_optimization_job_status",
            description="è·å–ç‰¹å®šä¼˜åŒ–ä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    },
                    "job_id": {
                        "type": "string",
                        "description": "ä»»åŠ¡ID"
                    }
                },
                "required": ["kb_id", "job_id"]
            }
        ),
        Tool(
            name="get_tagging_overview",
            description="è·å–çŸ¥è¯†åº“æ ‡ç­¾ç®¡ç†æ¦‚è§ˆï¼ŒåŒ…æ‹¬æ ‡æ³¨ç»Ÿè®¡å’Œæœªæ ‡æ³¨å†…å®¹",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="get_untagged_content",
            description="è·å–éœ€è¦æ ‡æ³¨çš„æœªæ ‡æ³¨æ–‡æ¡£ç‰‡æ®µ",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "è¿”å›çš„ç‰‡æ®µæ•°é‡",
                        "default": 10,
                        "minimum": 1,
                        "maximum": 50
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="start_smart_tagging",
            description="å¯åŠ¨æ™ºèƒ½æ ‡æ³¨ä»»åŠ¡ï¼Œå¯ä»¥å¯¹æ•´ä¸ªæ–‡æ¡£æˆ–ç‰¹å®šç‰‡æ®µè¿›è¡Œæ ‡æ³¨",
            inputSchema={
                "type": "object",
                "properties": {
                    "kb_id": {
                        "type": "string",
                        "description": "çŸ¥è¯†åº“ID"
                    },
                    "document_id": {
                        "type": "string",
                        "description": "è¦æ ‡æ³¨çš„æ–‡æ¡£IDï¼ˆå¯é€‰ï¼Œå¦‚æœæŒ‡å®šåˆ™æ ‡æ³¨æ•´ä¸ªæ–‡æ¡£ï¼‰"
                    },
                    "chunk_ids": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "è¦æ ‡æ³¨çš„ç‰‡æ®µIDåˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæŒ‡å®šåˆ™åªæ ‡æ³¨è¿™äº›ç‰‡æ®µï¼‰"
                    }
                },
                "required": ["kb_id"]
            }
        ),
        Tool(
            name="get_document_visual_preview",
            description="è·å–æ–‡æ¡£çš„å¯è§†åŒ–é¢„è§ˆä¿¡æ¯ï¼ŒåŒ…æ‹¬é¡µé¢æˆªå›¾",
            inputSchema={
                "type": "object",
                "properties": {
                    "document_id": {
                        "type": "string",
                        "description": "æ–‡æ¡£ID"
                    }
                },
                "required": ["document_id"]
            }
        ),
        Tool(
            name="get_screenshot_details",
            description="è·å–ç‰¹å®šæˆªå›¾çš„è¯¦ç»†ä¿¡æ¯",
            inputSchema={
                "type": "object",
                "properties": {
                    "screenshot_id": {
                        "type": "string",
                        "description": "æˆªå›¾ID"
                    }
                },
                "required": ["screenshot_id"]
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict) -> list[types.TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    base_url = os.getenv('KOSMOS_BASE_URL')
    if not base_url:
        return [types.TextContent(
            type="text",
            text="âŒ é”™è¯¯: æœªé…ç½®KOSMOS_BASE_URLç¯å¢ƒå˜é‡\n\nè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®:\nKOSMOS_BASE_URL=http://localhost:8000"
        )]
    
    username = os.getenv('KOSMOS_USERNAME')
    password = os.getenv('KOSMOS_PASSWORD')
    
    # æç¤ºè®¤è¯é…ç½®ï¼ˆä½†ä¸å¼ºåˆ¶è¦æ±‚ï¼Œå› ä¸ºå¯èƒ½æœ‰å…¬å¼€çŸ¥è¯†åº“ï¼‰
    auth_warning = ""
    if not username or not password:
        auth_warning = "\nâš ï¸  æç¤º: æœªé…ç½®KOSMOS_USERNAMEæˆ–KOSMOS_PASSWORDï¼Œåªèƒ½è®¿é—®å…¬å¼€çŸ¥è¯†åº“"
        
    try:
        async with KosmosClient(
            base_url=base_url,
            username=username,
            password=password,
        ) as client:
            
            if name == "list_knowledge_bases":
                result = await client.list_knowledge_bases()
                return [types.TextContent(
                    type="text",
                    text=f"# çŸ¥è¯†åº“åˆ—è¡¨\n\næ‰¾åˆ° {len(result)} ä¸ªçŸ¥è¯†åº“ï¼š\n\n" + 
                         "\n".join([f"- **{kb['name']}** ({kb['id']}): {kb.get('description', 'æ— æè¿°')}" 
                                   for kb in result])
                )]
                
            elif name == "get_knowledge_base":
                kb_id = arguments["kb_id"]
                result = await client.get_knowledge_base(kb_id)
                members_info = f"æˆå‘˜æ•°é‡: {len(result.get('members', []))}"
                return [types.TextContent(
                    type="text",
                    text=f"# çŸ¥è¯†åº“è¯¦æƒ…\n\n"
                         f"**åç§°**: {result['name']}\n"
                         f"**ID**: {result['id']}\n"
                         f"**æè¿°**: {result.get('description', 'æ— æè¿°')}\n"
                         f"**æ‰€æœ‰è€…**: {result.get('owner_username', result['owner_id'])}\n"
                         f"**æ˜¯å¦å…¬å¼€**: {'æ˜¯' if result['is_public'] else 'å¦'}\n"
                         f"**{members_info}**\n"
                         f"**åˆ›å»ºæ—¶é—´**: {result['created_at']}\n"
                         f"**æ ‡ç­¾å­—å…¸**: {len(result.get('tag_dictionary', {}))} ä¸ªæ ‡ç­¾"
                )]
                
            elif name == "search_knowledge_base":
                kb_id = arguments["kb_id"]
                query = arguments["query"]
                top_k = arguments.get("top_k", 10)
                result = await client.search_knowledge_base(kb_id, query, top_k)
                
                search_results = result.get("results", [])
                recommended_tags = result.get("recommended_tags", [])
                
                response = f"# æœç´¢ç»“æœ\n\næŸ¥è¯¢: **{query}**\næ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœ:\n\n"
                
                for i, item in enumerate(search_results, 1):
                    tags_str = ", ".join(item.get("tags", [])) or "æ— æ ‡ç­¾"
                    response += f"## ç»“æœ {i} (ç›¸ä¼¼åº¦: {item['score']:.3f})\n"
                    response += f"**æ–‡æ¡£ID**: {item['document_id']}\n"
                    response += f"**ç‰‡æ®µID**: {item['chunk_id']}\n"
                    response += f"**æ ‡ç­¾**: {tags_str}\n"
                    response += f"**å†…å®¹**:\n{item['content'][:500]}{'...' if len(item['content']) > 500 else ''}\n\n"
                
                if recommended_tags:
                    response += f"## æ¨èæ ‡ç­¾\n\n"
                    for tag in recommended_tags[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ¨èæ ‡ç­¾
                        response += f"- {tag['tag']} (é¢‘ç‡: {tag['freq']}, åˆ†æ•°: {tag['eig_score']:.3f})\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_chunk":
                chunk_id = arguments["chunk_id"]
                result = await client.get_chunk(chunk_id)
                tags_str = ", ".join(result.get("tags", [])) or "æ— æ ‡ç­¾"
                return [types.TextContent(
                    type="text",
                    text=f"# æ–‡æ¡£ç‰‡æ®µè¯¦æƒ…\n\n"
                         f"**ç‰‡æ®µID**: {result['id']}\n"
                         f"**çŸ¥è¯†åº“ID**: {result['kb_id']}\n"
                         f"**æ–‡æ¡£ID**: {result['document_id']}\n"
                         f"**ç‰‡æ®µç´¢å¼•**: {result['chunk_index']}\n"
                         f"**æ ‡ç­¾**: {tags_str}\n"
                         f"**åˆ›å»ºæ—¶é—´**: {result['created_at']}\n\n"
                         f"**å†…å®¹**:\n{result['content']}"
                )]
                
            elif name == "get_knowledge_base_stats":
                kb_id = arguments["kb_id"]
                result = await client.get_knowledge_base_stats(kb_id)
                return [types.TextContent(
                    type="text",
                    text=f"# çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯\n\n{json.dumps(result, ensure_ascii=False, indent=2)}"
                )]
                
            elif name == "monitor_knowledge_base_health":
                kb_id = arguments["kb_id"]
                result = await client.get_knowledge_base_health(kb_id)
                
                # æ ¼å¼åŒ–å¥åº·åº¦ä¿¡æ¯
                progress = result.get('progress_metrics', {})
                quality = result.get('quality_metrics', {})
                
                response = f"# çŸ¥è¯†åº“å¥åº·åº¦ç›‘æµ‹\n\n"
                response += f"**çŸ¥è¯†åº“ID**: {result['kb_id']}\n"
                response += f"**æœ€åæ›´æ–°**: {result.get('last_updated', 'N/A')}\n\n"
                
                # è¿›åº¦æŒ‡æ ‡
                response += f"## ğŸ“Š è¿›åº¦æŒ‡æ ‡\n\n"
                response += f"- **å½“å‰è¿­ä»£**: {progress.get('current_iteration', 0)}/{progress.get('total_iterations', 100)}\n"
                response += f"- **è¿›åº¦**: {progress.get('progress_pct', 0):.1f}%\n"
                response += f"- **æ ‡ç­¾å­—å…¸å¤§å°**: {progress.get('current_tags_dictionary_size', 0)}/{progress.get('max_tags_dictionary_size', 1000)}\n"
                response += f"- **å®¹é‡ä½¿ç”¨**: {progress.get('capacity_pct', 0):.1f}%\n\n"
                
                # è´¨é‡æŒ‡æ ‡
                response += f"## ğŸ” è´¨é‡æŒ‡æ ‡\n\n"
                response += f"- **æ ‡æ³¨ä¸è¶³çš„æ–‡æ¡£**: {quality.get('under_annotated_docs_count', 0)} ä¸ª\n"
                response += f"- **æ ‡æ³¨è¿‡åº¦çš„æ–‡æ¡£**: {quality.get('over_annotated_docs_count', 0)} ä¸ª\n"
                response += f"- **æ— æ³•åŒºåˆ†çš„æ–‡æ¡£**: {quality.get('indistinguishable_docs_count', 0)} ä¸ª\n"
                response += f"- **ä½¿ç”¨ä¸è¶³çš„æ ‡ç­¾**: {quality.get('under_used_tags_count', 0)} ä¸ª\n"
                response += f"- **ä½¿ç”¨è¿‡åº¦çš„æ ‡ç­¾**: {quality.get('over_used_tags_count', 0)} ä¸ª\n\n"
                
                # å¼‚å¸¸æ–‡æ¡£æ¦‚è§ˆ
                abnormal_docs = result.get('abnormal_documents', [])
                if abnormal_docs:
                    response += f"## âš ï¸ å¼‚å¸¸æ–‡æ¡£æ¦‚è§ˆ\n\n"
                    response += f"å‘ç° {len(abnormal_docs)} ä¸ªå¼‚å¸¸æ–‡æ¡£ã€‚ä½¿ç”¨ `get_problematic_documents` å·¥å…·æŸ¥çœ‹è¯¦æƒ…ã€‚\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_problematic_documents":
                kb_id = arguments["kb_id"]
                limit = arguments.get("samples_per_type", 3)
                result = await client.get_abnormal_documents(kb_id, limit)
                
                abnormal_docs = result.get('abnormal_documents', [])
                grouped_docs = result.get('abnormal_documents_by_type', {})
                
                response = f"# æœ‰é—®é¢˜çš„æ–‡æ¡£\n\n"
                response += f"**çŸ¥è¯†åº“ID**: {kb_id}\n"
                response += f"**æ€»å¼‚å¸¸æ–‡æ¡£æ•°**: {result.get('total_count', len(abnormal_docs))}\n"
                response += f"**æ¯ç±»æ˜¾ç¤ºæ ·æœ¬æ•°**: {limit}\n\n"
                
                # æŒ‰ç±»å‹æ˜¾ç¤ºå¼‚å¸¸æ–‡æ¡£
                type_names = {
                    'under_annotated': 'æ ‡æ³¨ä¸è¶³',
                    'over_annotated': 'æ ‡æ³¨è¿‡åº¦',
                    'indistinguishable': 'æ— æ³•åŒºåˆ†'
                }
                
                for anomaly_type, docs in grouped_docs.items():
                    type_name = type_names.get(anomaly_type, anomaly_type)
                    response += f"## {type_name}æ–‡æ¡£ ({len(docs)} ä¸ªæ ·æœ¬)\n\n"
                    
                    for i, doc in enumerate(docs, 1):
                        content_preview = doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content']
                        tags_str = ", ".join(doc.get('current_tags', [])) or "æ— æ ‡ç­¾"
                        
                        response += f"### æ ·æœ¬ {i}\n"
                        response += f"**æ–‡æ¡£ID**: {doc['doc_id']}\n"
                        response += f"**å¼‚å¸¸åŸå› **: {doc.get('reason', 'N/A')}\n"
                        response += f"**å½“å‰æ ‡ç­¾**: {tags_str}\n"
                        response += f"**å†…å®¹é¢„è§ˆ**: {content_preview}\n\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "start_health_optimization":
                kb_id = arguments["kb_id"]
                mode = arguments.get("mode", "shadow")
                batch_size = arguments.get("batch_size", 10)
                
                result = await client.start_health_optimization(kb_id, mode, batch_size)
                
                mode_desc = "å½±å­æ¨¡å¼ï¼ˆä»…åˆ†æï¼‰" if mode == "shadow" else "ç¼–è¾‘æ¨¡å¼ï¼ˆè‡ªåŠ¨ä¿®å¤ï¼‰"
                response = f"# å¥åº·åº¦ä¼˜åŒ–ä»»åŠ¡å·²å¯åŠ¨\n\n"
                response += f"**çŸ¥è¯†åº“ID**: {kb_id}\n"
                response += f"**ä¼˜åŒ–æ¨¡å¼**: {mode_desc}\n"
                response += f"**æ‰¹å¤„ç†å¤§å°**: {batch_size}\n"
                response += f"**ä»»åŠ¡ID**: {result.get('job_id', 'N/A')}\n\n"
                response += f"**çŠ¶æ€**: {result.get('message', 'ä»»åŠ¡å·²å¯åŠ¨')}\n\n"
                response += f"ğŸ’¡ ä½¿ç”¨ `get_optimization_job_status` å·¥å…·æŸ¥çœ‹ä»»åŠ¡è¿›åº¦ã€‚"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_optimization_jobs":
                kb_id = arguments["kb_id"]
                result = await client.get_optimization_jobs(kb_id)
                
                jobs = result.get('jobs', [])
                response = f"# ä¼˜åŒ–ä»»åŠ¡åˆ—è¡¨\n\n"
                response += f"**çŸ¥è¯†åº“ID**: {kb_id}\n"
                response += f"**ä»»åŠ¡æ€»æ•°**: {len(jobs)}\n\n"
                
                if jobs:
                    for job in jobs:
                        mode_desc = {
                            'shadow': 'å½±å­æ¨¡å¼',
                            'edit': 'ç¼–è¾‘æ¨¡å¼',
                            'annotate': 'æ ‡æ³¨æ¨¡å¼'
                        }.get(job.get('mode', ''), job.get('mode', ''))
                        
                        response += f"## ä»»åŠ¡ {job['job_id']}\n"
                        response += f"- **æ¨¡å¼**: {mode_desc}\n"
                        response += f"- **çŠ¶æ€**: {job['status']}\n"
                        response += f"- **æ‰¹å¤„ç†å¤§å°**: {job.get('batch_size', 'N/A')}\n"
                        response += f"- **è‡ªåŠ¨åº”ç”¨**: {'æ˜¯' if job.get('auto_apply') else 'å¦'}\n"
                        response += f"- **åˆ›å»ºæ—¶é—´**: {job['created_at']}\n"
                        response += f"- **æ›´æ–°æ—¶é—´**: {job['updated_at']}\n"
                        if job.get('error_message'):
                            response += f"- **é”™è¯¯ä¿¡æ¯**: {job['error_message']}\n"
                        response += "\n"
                else:
                    response += "æš‚æ— ä¼˜åŒ–ä»»åŠ¡ã€‚"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_optimization_job_status":
                kb_id = arguments["kb_id"]
                job_id = arguments["job_id"]
                result = await client.get_optimization_job_status(kb_id, job_id)
                
                mode_desc = {
                    'shadow': 'å½±å­æ¨¡å¼',
                    'edit': 'ç¼–è¾‘æ¨¡å¼',
                    'annotate': 'æ ‡æ³¨æ¨¡å¼'
                }.get(result.get('mode', ''), result.get('mode', ''))
                
                response = f"# ä¼˜åŒ–ä»»åŠ¡çŠ¶æ€\n\n"
                response += f"**ä»»åŠ¡ID**: {result['job_id']}\n"
                response += f"**çŸ¥è¯†åº“ID**: {result['kb_id']}\n"
                response += f"**æ¨¡å¼**: {mode_desc}\n"
                response += f"**çŠ¶æ€**: {result['status']}\n"
                response += f"**æ‰¹å¤„ç†å¤§å°**: {result.get('batch_size', 'N/A')}\n"
                response += f"**è‡ªåŠ¨åº”ç”¨**: {'æ˜¯' if result.get('auto_apply') else 'å¦'}\n"
                response += f"**åˆ›å»ºæ—¶é—´**: {result['created_at']}\n"
                response += f"**æ›´æ–°æ—¶é—´**: {result['updated_at']}\n"
                
                if result.get('error_message'):
                    response += f"**é”™è¯¯ä¿¡æ¯**: {result['error_message']}\n"
                
                # æ˜¾ç¤ºç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
                if result.get('result'):
                    response += f"\n## ä»»åŠ¡ç»“æœ\n\n"
                    task_result = result['result']
                    if isinstance(task_result, dict):
                        if task_result.get('operations'):
                            response += f"- **æ‰§è¡Œçš„æ“ä½œæ•°**: {len(task_result['operations'])}\n"
                        if task_result.get('annotations'):
                            response += f"- **ç”Ÿæˆçš„æ ‡æ³¨æ•°**: {len(task_result['annotations'])}\n"
                        if task_result.get('reasoning'):
                            response += f"- **æ¨ç†è¿‡ç¨‹**: {task_result['reasoning'][:200]}...\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_tagging_overview":
                kb_id = arguments["kb_id"]
                stats_result = await client.get_tagging_stats(kb_id)
                untagged_result = await client.get_untagged_chunks(kb_id, 5)  # è·å–å°‘é‡æ ·æœ¬
                
                response = f"# æ ‡ç­¾ç®¡ç†æ¦‚è§ˆ\n\n"
                response += f"**çŸ¥è¯†åº“ID**: {kb_id}\n\n"
                
                # æ ‡æ³¨ç»Ÿè®¡
                response += f"## ğŸ“ˆ æ ‡æ³¨ç»Ÿè®¡\n\n"
                response += f"{json.dumps(stats_result, ensure_ascii=False, indent=2)}\n\n"
                
                # æœªæ ‡æ³¨å†…å®¹
                response += f"## ğŸ“ æœªæ ‡æ³¨å†…å®¹\n\n"
                response += f"**æœªæ ‡æ³¨ç‰‡æ®µæ€»æ•°**: {untagged_result.get('total_untagged', 0)}\n"
                
                chunks = untagged_result.get('chunks', [])
                if chunks:
                    response += f"**æ ·æœ¬ç‰‡æ®µ** (æ˜¾ç¤ºå‰5ä¸ª):\n\n"
                    for i, chunk in enumerate(chunks, 1):
                        response += f"### ç‰‡æ®µ {i}\n"
                        response += f"**ç‰‡æ®µID**: {chunk['id']}\n"
                        response += f"**æ–‡æ¡£ID**: {chunk['document_id']}\n"
                        response += f"**å†…å®¹**: {chunk['content']}\n\n"
                else:
                    response += "âœ… æ‰€æœ‰ç‰‡æ®µéƒ½å·²æ ‡æ³¨ï¼\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_untagged_content":
                kb_id = arguments["kb_id"]
                limit = arguments.get("limit", 10)
                result = await client.get_untagged_chunks(kb_id, limit)
                
                response = f"# æœªæ ‡æ³¨å†…å®¹\n\n"
                response += f"**çŸ¥è¯†åº“ID**: {kb_id}\n"
                response += f"**æœªæ ‡æ³¨ç‰‡æ®µæ€»æ•°**: {result.get('total_untagged', 0)}\n"
                response += f"**æ˜¾ç¤ºæ•°é‡**: {limit}\n\n"
                
                chunks = result.get('chunks', [])
                if chunks:
                    for i, chunk in enumerate(chunks, 1):
                        response += f"## ç‰‡æ®µ {i}\n"
                        response += f"**ç‰‡æ®µID**: {chunk['id']}\n"
                        response += f"**æ–‡æ¡£ID**: {chunk['document_id']}\n"
                        response += f"**ç‰‡æ®µç´¢å¼•**: {chunk['chunk_index']}\n"
                        response += f"**å†…å®¹**: {chunk['content']}\n\n"
                else:
                    response += "âœ… æ‰€æœ‰ç‰‡æ®µéƒ½å·²æ ‡æ³¨ï¼\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "start_smart_tagging":
                kb_id = arguments["kb_id"]
                document_id = arguments.get("document_id")
                chunk_ids = arguments.get("chunk_ids")
                
                result = await client.start_tagging_task(kb_id, document_id, chunk_ids)
                
                response = f"# æ™ºèƒ½æ ‡æ³¨ä»»åŠ¡\n\n"
                response += f"**çŸ¥è¯†åº“ID**: {kb_id}\n"
                
                if document_id:
                    response += f"**æ ‡æ³¨ç›®æ ‡**: æ–‡æ¡£ {document_id}\n"
                elif chunk_ids:
                    response += f"**æ ‡æ³¨ç›®æ ‡**: {len(chunk_ids)} ä¸ªæŒ‡å®šç‰‡æ®µ\n"
                else:
                    response += f"**æ ‡æ³¨ç›®æ ‡**: æ‰€æœ‰æœªæ ‡æ³¨ç‰‡æ®µ\n"
                
                response += f"**ä»»åŠ¡çŠ¶æ€**: {result.get('success', False)}\n"
                response += f"**å¤„ç†ç»“æœ**: {result.get('message', 'N/A')}\n\n"
                
                # æ˜¾ç¤ºæ ‡æ³¨ç»“æœ
                if result.get('tagged_chunks'):
                    response += f"## æ ‡æ³¨ç»“æœ\n\n"
                    for chunk_result in result['tagged_chunks'][:5]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                        response += f"- **ç‰‡æ®µ {chunk_result['chunk_id']}**: {', '.join(chunk_result.get('tags', []))}\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_document_visual_preview":
                document_id = arguments["document_id"]
                result = await client.get_document_screenshots(document_id)
                
                data = result.get('data', {})
                screenshots = data.get('screenshots', [])
                
                response = f"# æ–‡æ¡£å¯è§†åŒ–é¢„è§ˆ\n\n"
                response += f"**æ–‡æ¡£ID**: {document_id}\n"
                response += f"**æ€»é¡µæ•°**: {data.get('total_pages', 0)}\n\n"
                
                if screenshots:
                    response += f"## é¡µé¢æˆªå›¾\n\n"
                    for screenshot in screenshots:
                        response += f"### ç¬¬ {screenshot['page_number']} é¡µ\n"
                        response += f"**æˆªå›¾ID**: {screenshot['id']}\n"
                        response += f"**å°ºå¯¸**: {screenshot['width']} Ã— {screenshot['height']}\n"
                        response += f"**åˆ›å»ºæ—¶é—´**: {screenshot.get('created_at', 'N/A')}\n\n"
                        response += f"ğŸ’¡ ä½¿ç”¨ `get_screenshot_details` å·¥å…·æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ã€‚\n\n"
                else:
                    response += "ğŸ“„ è¯¥æ–‡æ¡£æš‚æ— å¯è§†åŒ–é¢„è§ˆã€‚\n"
                
                return [types.TextContent(type="text", text=response)]
                
            elif name == "get_screenshot_details":
                screenshot_id = arguments["screenshot_id"]
                result = await client.get_screenshot_info(screenshot_id)
                
                data = result.get('data', {})
                response = f"# æˆªå›¾è¯¦ç»†ä¿¡æ¯\n\n"
                response += f"**æˆªå›¾ID**: {screenshot_id}\n"
                response += f"**é¡µç **: {data.get('page_number', 'N/A')}\n"
                response += f"**å°ºå¯¸**: {data.get('width', 'N/A')} Ã— {data.get('height', 'N/A')}\n"
                response += f"**åˆ›å»ºæ—¶é—´**: {data.get('created_at', 'N/A')}\n\n"
                response += f"ğŸ’¡ æˆªå›¾æ–‡ä»¶å¯é€šè¿‡ `/screenshots/{screenshot_id}/image` ç«¯ç‚¹è®¿é—®ã€‚\n"
                
                return [types.TextContent(type="text", text=response)]
                
            else:
                raise ValueError(f"æœªçŸ¥å·¥å…·: {name}")
                
    except Exception as e:
        error_message = f"âŒ é”™è¯¯: {str(e)}{auth_warning}"
        
        # ä¸ºè®¤è¯ç›¸å…³é”™è¯¯æä¾›é¢å¤–æç¤º
        if "403" in str(e) or "401" in str(e) or "æœªæˆæƒ" in str(e) or "ç¦æ­¢è®¿é—®" in str(e):
            error_message += "\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:\n1. ç¡®ä¿åœ¨.envæ–‡ä»¶ä¸­é…ç½®äº†æ­£ç¡®çš„KOSMOS_USERNAMEå’ŒKOSMOS_PASSWORD\n2. æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è®¿é—®è¯¥çŸ¥è¯†åº“çš„æƒé™\n3. ç¡®è®¤çŸ¥è¯†åº“æ˜¯å¦ä¸ºå…¬å¼€çŠ¶æ€"
        
        return [types.TextContent(
            type="text",
            text=error_message
        )]

async def main():
    """ä¸»å‡½æ•°"""
    # è·å–ç¯å¢ƒå˜é‡
    base_url = os.getenv('KOSMOS_BASE_URL')
    if not base_url:
        print("é”™è¯¯: è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®KOSMOS_BASE_URL")
        return
    
    # è¿è¡ŒæœåŠ¡å™¨
    from mcp.server.stdio import stdio_server
    
    async with stdio_server() as streams:
        await server.run(
            streams[0], 
            streams[1], 
            InitializationOptions(
                server_name="kosmos-knowledge-base",
                server_version="1.0.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={}
                )
            )
        )

if __name__ == "__main__":
    asyncio.run(main())